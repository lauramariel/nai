{
    "cells": [
        {
            "cell_type": "markdown",
            "id": "a26b22c3-c09b-4bec-93fa-65b62ffa91f1",
            "metadata": {},
            "source": [
                "### Import Python Modules\n",
                "\n",
                "Import the required Python modules from Langchain.\n",
                "\n",
                "* **RecursiveCharacterTextSplitter** - Text splitter. This is required to split our Nutanix Bible content into chunks.\n",
                "* **HuggingFaceEmbeddings** - This allows access to embedding models in Hugging Face\n",
                "* **Milvus** - This allows the code to use and manage our Milvus Vector DB.\n",
                "* **WebBaseLoader** - This loads HTML content into a document format we can use with our DB."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "834b5648-3639-46a5-814c-f91d74b8f48d",
            "metadata": {},
            "outputs": [],
            "source": [
                "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
                "from langchain.embeddings import HuggingFaceEmbeddings\n",
                "from langchain.vectorstores import Milvus\n",
                "from langchain.document_loaders import WebBaseLoader"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "3deba426-0bf0-4f7d-ab41-89030470200a",
            "metadata": {},
            "source": [
                "### Initialize an instance of HuggingFaceEmbeddings\n",
                "\n",
                "This code is initializing an instance of [HuggingFaceEmbeddings](https://api.python.langchain.com/en/latest/embeddings/langchain_community.embeddings.huggingface.HuggingFaceEmbeddings.html) from Langchain, which allows us to access the [Sentence Transformers](https://huggingface.co/sentence-transformers) embedding models in Hugging Face.\n",
                "\n",
                "An embedding is a numerical representation of objects for use in machine learning systems. The text content from the Nutanix Bible needs to be translated into multi-dimensional vectors. Like the foundational models that can be used for chatbots (e.g. LLama2), there are many pre-trained embedding models to help us do this translation. These models have learned from a huge amount of text to understand how words are normally used and in what contexts those words are used in.\n",
                "\n",
                "In this lab, we are using the [sentence-transformers/all-mpnet-base-v2](https://huggingface.co/sentence-transformers/all-mpnet-base-v2) embedding model.\n",
                "\n",
                "#### Note\n",
                "When running this code, you can ignore the following warning:\n",
                "\n",
                "```\n",
                "/home/jovyan/.local/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
                "```"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "f99dcc5a-8da1-4451-a88e-7cc74d304125",
            "metadata": {},
            "outputs": [],
            "source": [
                "modelPath = \"sentence-transformers/all-mpnet-base-v2\"\n",
                "\n",
                "model_kwargs = {}\n",
                "\n",
                "# Create a dictionary with encoding options, specifically setting 'normalize_embeddings' to False\n",
                "encode_kwargs = {'normalize_embeddings': True}\n",
                "\n",
                "# Initialize an instance of HuggingFaceEmbeddings with the specified parameters\n",
                "embeddings = HuggingFaceEmbeddings(\n",
                "    model_name=modelPath,     # Provide the pre-trained model's path\n",
                "    model_kwargs=model_kwargs, # Pass the model configuration options\n",
                "    encode_kwargs=encode_kwargs # Pass the encoding options\n",
                ")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "24f394d9-f016-4f7e-be88-9f0c6afad4a1",
            "metadata": {},
            "source": [
                "### Load the Nutanix Bible content\n",
                "\n",
                "This code uses the <a href=\"https://python.langchain.com/docs/integrations/document_loaders/web_base\" target=\"_blank\">WebBaseLoader</a> component of Langchain to load our Nutanix Bible content into a document format that can be ingested into the database."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "0fd1b630-2c32-47b9-9f8f-397dca2a5ddf",
            "metadata": {},
            "outputs": [],
            "source": [
                "loader = WebBaseLoader(\"https://www.nutanixbible.com/classic\")\n",
                "data = loader.load()"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "a79fab1b-820e-472e-99f9-909f0bfb01ff",
            "metadata": {},
            "source": [
                "### Split contents of the data object\n",
                "\n",
                "We don’t want to store the data as one vector. In this code, we’ll split up the data into chunks of 500 characters each with the [RecursiveCharacterTextSplitter](https://api.python.langchain.com/en/latest/text_splitter/langchain.text_splitter.RecursiveCharacterTextSplitter.html) component of Langchain."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "55121404-05fe-453c-9291-3dbe0771a6d7",
            "metadata": {},
            "outputs": [],
            "source": [
                "text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=0)\n",
                "docs = text_splitter.split_documents(data)"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "2e7e9d49-4f5f-4fe4-98de-2f9383e7d618",
            "metadata": {},
            "source": [
                "### Ingest the documents into Milvus\n",
                "\n",
                "In this code, we'll ingest our documents into Milvus along with our embeddings object, which will ingest all of our documents and create a vector embedding of each.\n",
                "\n",
                "Note that we are using the internal name of the database service instead of an IP."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "a4b97617-3de0-4c10-b38a-c3a4e74e2334",
            "metadata": {},
            "outputs": [],
            "source": [
                "vector_db = Milvus.from_documents(\n",
                "    docs,\n",
                "    embeddings,\n",
                "    collection_name=\"nutanixbible_web\",\n",
                "    connection_args={\"host\":\"10.38.35.41\",\"port\":\"19530\"}\n",
                ")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "000aadb6-84f3-4dd8-bf6e-ec917e510e75",
            "metadata": {},
            "source": [
                "### Return to the Lab Guide\n",
                "\n",
                "Move onto the **View Documents in Milvus** section of the lab guide."
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3 (ipykernel)",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.11.5"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}
